[project]
dependencies = [
    "llama-stack @ git+https://github.com/meta-llama/llama-stack.git@main",
    "ramalama==0.7.5",
    "urllib3",
    "six",
    "pydantic",
    "aiohttp",
    "aiosqlite",
    "datasets",
    "fastapi",
    "httpx",
    "numpy",
    "openai",
    "opentelemetry-exporter-otlp-proto-http",
    "opentelemetry-sdk",
    "requests",
    "uvicorn",
]

name = "llama-stack-provider-ramalama"
version = "0.1.0"
description = "Llama Stack Provider for Ramalama Inference"
readme = "README.md"
requires-python = ">=3.10"

[tool.ruff]
extend-exclude = ["*.ipynb"]

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
